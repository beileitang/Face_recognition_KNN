#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Sat Mar 16 21:43:25 2019

@author: gloria
"""

import constant
import download_data

import pandas as pd
import numpy as np
import glob
import os

np.random.seed(constant.RANDOM_SEED)
#%%
# =============================================================================
# OLD PREPROCESSING... WILL BE DEPRECATED
# 2019.MARCH.24: YU_HSIEN ONLY TESTED WITH MALE ACTORS
# =============================================================================
if __name__ == "__main__":
    
#    # check if directories exist
#    print('Cheking directories...')
#    download_data.mkdir_if_dne(constant.UNCROPPED_DIR_M)
#    download_data.mkdir_if_dne(constant.CROPPED_DIR_M)
#    download_data.mkdir_if_dne(constant.UNCROPPED_DIR_F)
#    download_data.mkdir_if_dne(constant.CROPPED_DIR_F)
#    
#    
#    # process dataframe to make sure which files to download
#    df_M = download_data.process_data_df(constant.act,constant.MALE_DF, constant.UNCROPPED_DIR_M)
#    df_F = download_data.process_data_df(constant.act,constant.FEMALE_DF, constant.UNCROPPED_DIR_F)
#    
#    #download files...
#    files_timedout_M = download_data.download(constant.act, df_M)
#    files_timedout_F = download_data.download(constant.act, df_F)
#    
#    # process downloaded imsges and save them 
#    file_paths_M = glob.glob(constant.UNCROPPED_DIR_M + '*.jpg') # i got 467 male images
#    empty_file_M,error_file_M = download_data.get_processed(df_M, file_paths_M, constant.CROPPED_DIR_M) 
#    '''
#    Daniel Radcliffe  171  
#    Gerard Butler     146  
#    Michael Vartan    150  
#    '''
#    #plz confirm 43 of male images is empty
#    # i.e. len(empty_file) ==43
#    file_paths_F = glob.glob(constant.UNCROPPED_DIR_F + '*.jpg') # i got 467 images
#    #NOTE BROKEN FILE
#    BROKEN_FILE = 'harmon33.jpg' # THIS ONE DOESNT EXIST ON FLICKR ANYMORE
#    file_paths_F = [f for f in file_paths_F if BROKEN_FILE not in f]
#    empty_file_F, error_file_F = download_data.get_processed(df_F, file_paths_F, constant.CROPPED_DIR_F) 
#    #plz confirm 43 of them is empty
#    # i.e. len(empty_file) ==43
#   =============================================================================
#   OLD PREPROCESSING... WILL BE DEPRECATED
#   2019.MARCH.31: YU_HSIEN downloaded new files 
#   this is how to process them
#   =============================================================================
    print('make resized dir if dir doesnt exist')
    download_data.mkdir_if_dne(constant.RESIZED_GRAY_IMG_DIR)
    
    uncropped = []
    for actor in constant.ACTOR_LIST:
        files = download_data.get_actor_img(constant.UNCROPPED_IMG_DIR, actor)
        uncropped.extend(files)
    
    resized = glob.glob(constant.RESIZED_GRAY_IMG_DIR + "*")
    if not resized:  
        # trun cropped images into grayscale and resize
        print('%s is empty! start processing images' % constant.RESIZED_GRAY_IMG_DIR)
        for actor in constant.ACTOR_LIST:
            cropped_files = download_data.get_actor_img(constant.CROPPED_IMG_DIR, actor)
            resized_images = [download_data.process_cropped_image(file) for file in cropped_files]
            resized.extend(resized_images)
    else:
        print('loaded resized imgs')
    
    uncropped_df = pd.DataFrame({'uncropped_path':uncropped})
    uncropped_df['img_id'] = uncropped_df.uncropped_path.str.extract(r'(\d+)')
    uncropped_df['actor'] = uncropped_df['uncropped_path'].str.extract(r'uncropped_images/(.*)/')

    
    
    df = pd.DataFrame({'resized_path':resized})
    df['actor'] = df['resized_path'].str.extract(r'resized_images/(.*)_[0-9]')
    df['img_id'] = df["resized_path"].apply(lambda x: os.path.splitext(os.path.basename(x))[0].split('_')[-1])
    df = df[['actor', 'img_id', 'resized_path']]
    df.sort_values('actor',axis=0,inplace = True)
    df = df.reset_index(drop = True)
    underline_actor = ["_".join(x.split()) for x in constant.ACTOR_LIST]
    df['Gender'] = np.where(df.actor.isin(underline_actor[:3]), 'M', 'F')
    
    df3 = pd.merge(df, uncropped_df, how='inner', on=['img_id'])
    df3.rename(columns={'actor_x':'actor'}, inplace=True)
 
    
#    uncropped_images = [download_data.read_in_and_flattened_images(path) for path in df3.uncropped_path.values]
#    cropped_images = [download_data.read_in_and_flattened_images(path) for path in df3.resized_path.values]



    #%% RANDOMLY CHOOSE 3 SAMPLES
    
    '''
    Part 1 (10%)
    Describe the dataset of faces. 
    In particular, provide at least three examples of the images in the dataset,
     as well as at least three examples of cropped out faces. 
    Comment on the quality of the annotation of the dataset: are the bounding boxes accurate? 
    Can the cropped-out faces be aligned with each other?
    '''
    import shutil
        
    download_data.mkdir_if_dne(constant.PART1_SAMPLE_DIR)
    
    # randomly choose 3 sample images
    part1_samples = df3.sample(3,random_state = constant.RANDOM_SEED)
    
    # find cropped file names
    cropped_samples = constant.CROPPED_IMG_DIR + part1_samples.actor + '/' + part1_samples.actor + \
    '_'+ part1_samples.img_id + '.png'
    cropped_samples = cropped_samples.tolist()
    
    # find uncropped file names
    uncropped_samples = constant.UNCROPPED_IMG_DIR + part1_samples.actor.str.replace("_", " ")  + '/'+\
    part1_samples.actor.str.replace("_", " ") + '_'+ part1_samples.img_id + '.jpg'
    uncropped_samples = uncropped_samples.tolist()
    
    # copy file to folder
    def copy_to_dir(list_of_files):
        for i in range(len(list_of_files)):
            file_name = os.path.basename(list_of_files[i])
            to_dir = constant.PART1_SAMPLE_DIR + file_name
            shutil.copyfile(list_of_files[i], to_dir)
    
    copy_to_dir(cropped_samples)
    copy_to_dir(uncropped_samples)
    
    #%%
    '''
    Part 2 (5%)
    Separate the dataset into three non-overlapping parts: 
        the training set (100 face images per actor), 
        the validation set (10 face images per actor), and
        the test set (10 face images per actor).
    For the report, describe how you did that. (Any method is fine).
    The training set will contain faces whose labels you assume you know. 
    The test set and the validation set will contain faces whose labels you pretend to not know and will attempt to determine using the data in the training set. 
    You will use the performance on the validation set to tune the K, and you will then report the final performance on the test set.
    '''
    sample_df = df3.groupby('actor').apply(lambda s: s.sample(120,random_state = constant.RANDOM_SEED))
    
    training_df= sample_df.groupby('actor').apply(lambda t: t[:100])
    training_resized_paths = training_df.resized_path.tolist()
    training_resized_imgs_flatten = [download_data.read_in_and_flattened_images(path) for path in training_resized_paths]
    training_resized_imgs_flatten = np.asarray(training_resized_imgs_flatten)
    training_resized_imgs = [download_data.read_in_img(path) for path in training_resized_paths]
    training_labels = training_df.actor.values
    
    validation_df = sample_df.groupby('actor').apply(lambda t: t[101:111])
    validation_resized_paths = validation_df.resized_path.tolist()
    validation_resized_imgs_flatten = [download_data.read_in_and_flattened_images(path) for path in validation_resized_paths]
    validation_resized_imgs_flatten = np.asarray(validation_resized_imgs_flatten)
    validation_resized_imgs = [download_data.read_in_img(path) for path in validation_resized_paths]
    validation_labels = validation_df.actor.values

    
    testing_df = sample_df.groupby('actor').apply(lambda t: t[-10:])    
    testing_resized_paths = testing_df.resized_path.tolist()
    testing_resized_imgs_flatten = [download_data.read_in_and_flattened_images(path) for path in testing_resized_paths]
    testing_resized_imgs_flatten = np.asarray(testing_resized_imgs_flatten)
    testing_resized_imgs = [download_data.read_in_img(path) for path in testing_resized_paths]
    testing_labels = testing_df.actor.values
    
    
    
    
    
   #%%
    '''
    Part 3 (45%)
    Write code to recognize faces from the set of faces act using K-Nearest Neighbours (note that face recognition is a classification task!). Determine the K using the validation set, and the report the performance on the test set. Here and elsewhere in the project, use the L2 distance between the flattened images of cropped-out faces in order to find the nearest neighbours.
    
    Note: the reason you need to use both a validation set and a test set is that picking the best k by using the validation set and then reporting the performance on the same set makes it so that you report artificially high performance. A better measure is obtained by picking the parameters of the algorithm using a validation set, and then measuring the performance on a separate test set.
    
    The performance you obtain will likely be around 50% or a little higher
    
    In addition to the performance on the test set, in your report, display 5 failure cases (where the majority of the k nearest neighbours of a test face are not the same person as the test person). Display both the face to be recognized and its 5 nearest neighbours.
    '''
    from knn_class import *
    
<<<<<<< HEAD
    predicted_label = []
    # 要一个一个的放人名哦 ！！！
    for val in validation_resized_imgs_flatten:
        neighbors = cal_neighbours(training_resized_imgs_flatten,
                               training_labels,val,10)
        neighbors_labels = [n[2] for n in neighbors]
        predicted_label.append(winner_vote(neighbors_labels)
        errors = zero_one_loss(validation_labels,predicted_label)
    
        
    
    #neighbors_labels = [n[2] for n in neighbors]
    #validation_labels = validation_df.actor.tolist()
    #winner_vote(neighbors_labels)
    #%%
from knn_class import *
#for val in validation_resized_imgs_flatten:
neighbors = cal_neighbours(training_resized_imgs_flatten,training_labels,validation_resized_imgs_flatten[10],3
                           )

#neighbors_labels_test = [i[2] for i in neighbors]
#winner_vote(neighbors_labels_test)


    
    #%%
   # 算出来test label 跟validation 的predict
   neighbors_test = cal_neighbours(testing_resized_imgs_flatten,validation_labels,validation_resized_imgs_flatten,10)
   
   neighbors_labels_test = [i[2] for i in neighbors_test]
   winner_vote(neighbors_labels_test)
    
=======
    total_val_err = []
    for k in range(1,11):
        errors = np.zeros(len(validation_resized_imgs_flatten))
        for i in range(len(validation_resized_imgs_flatten)):
            neighbors = cal_neighbours(training_resized_imgs_flatten,training_labels,
                                   validation_resized_imgs_flatten[i],k)
            neighbors_labels_test = [i[2] for i in neighbors]
            predicted_val_label = winner_vote(neighbors_labels_test)
            if predicted_val_label[0][0] != validation_labels[i]:
                errors[i] = 1
        total_val_err.append(errors.mean())
    best_k = np.where(total_val_err==min(total_val_err))[0][0] + 1
 
>>>>>>> beb4fda0db7c7a5c1f82c6c38a1d3b4e4ae6ab82
   
    test_errors = np.zeros(len(testing_resized_imgs_flatten))
    for i in range(len(testing_resized_imgs_flatten)):
        neighbors_test = cal_neighbours(training_resized_imgs_flatten,training_labels,
                                   testing_resized_imgs_flatten[i],4)
        neighbors_test_label = [i[2] for i in neighbors_test]
        predicted_test_label = winner_vote(neighbors_test_label)
        if predicted_test_label[0][0] != testing_labels[i]:
            test_errors[i] = 1
    
    test_errors
    testing_df['test_errors'] = test_errors    
    #%%
    '''
    Part 4 (10%)
    Plot the performance on the test, train, and validation sets of the K-Nearest-Neighbours algorithm for various K. Make sure the axes of your graphs are correctly labelled. Explain why the plots look the way they do.
    '''
    #%%
    '''
    Part 5 (20%)
    Write code to determine, for every face in a set of faces, the gender of the person using K-Nearest-Neighbours. This should work in the same way as face recognition, except instead of each face being assigned a name, each face is considered to be simply either male or female. Again, use your validation set to select a k for the best performance (i.e., the proportion of faces whose gender was classified correctly), report the performance for the different k's for the validation set, and then report the results on the test set for the k that works best for the validation set. For this part, you should still use the set of actors act for both the test and the validation set.
    
    The performance you obtain will likely be around 80% or a little higher
    '''
    #%%
    '''
    Part 6 (10%)
    Now, evaluate the implementation in Part 5 on faces of actors who are not in the training set (i.e., actors other than the people in the set act.) Discuss the difference between the performance in Part 5 and the performance in Part 6.
    '''